{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N1EFIXH8gqDv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import clamp\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import glob\n",
        "from natsort import natsorted\n",
        "import time\n",
        "\n",
        "class SemanticSearch:\n",
        "\n",
        "    def __init__(self, corpus_embeddings_path='C:/Users/Geraldus Wilsen/Documents/ProjectRekomendasiObat/data/corpus_dense_embeddings_sbert.npy', cluster_centroid_embeddings_path='cluster_centroid_data.h5'):\n",
        "        self.corpus_embeddings_path = corpus_embeddings_path\n",
        "        self.cluster_centroid_embeddings_path = cluster_centroid_embeddings_path\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def load_pretrained(self, from_pretrained:str=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"):\n",
        "        self.model = SentenceTransformer(from_pretrained)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def process(self, *corpora):\n",
        "        print('Encoding process using', self.device)\n",
        "        for corpus in corpora:\n",
        "\n",
        "            if len(corpus) > 100:\n",
        "                max_size = 100\n",
        "                smaller_batch = [corpus[i:i + max_size] for i in range(0, len(corpus), max_size)]\n",
        "                print(len(corpus), 'corpus separated into', len(smaller_batch), 'smaller batch')\n",
        "\n",
        "                i = 1\n",
        "                for batch in smaller_batch:\n",
        "                    mean_pooled = self.model.encode(batch)\n",
        "                    np.save(f'temp/temp_{i}.npy', mean_pooled)\n",
        "                    print(f\"Finish embed corpus, batch {i}\")\n",
        "                    i += 1\n",
        "                    time.sleep(10)\n",
        "\n",
        "            else:\n",
        "                mean_pooled = self.model.encode(corpus)\n",
        "                print(\"Finish embed query\")\n",
        "\n",
        "        temp_directories = natsorted(glob.glob(\"temp/*.npy\"))\n",
        "        if len(temp_directories) > 1:\n",
        "          corpus = []\n",
        "          for e in natsorted(glob.glob(\"temp/*.npy\")):\n",
        "              print(e)\n",
        "              corpus.append(np.load(e))\n",
        "              mean_pooled = np.vstack(corpus)\n",
        "              print('Success corpus append')\n",
        "              os.remove(e)\n",
        "          np.save('corpus_dense_embeddings_sbert.npy', mean_pooled)\n",
        "          print(f\"Finish embed corpus\")\n",
        "\n",
        "        return mean_pooled\n",
        "\n",
        "    def rank(self, corpus, query):\n",
        "\n",
        "        if os.path.exists(self.corpus_embeddings_path):\n",
        "            corpus_embeddings = np.load(self.corpus_embeddings_path)\n",
        "        else:\n",
        "            corpus_embeddings = self.process(corpus)\n",
        "        query_embeddings = self.process([query])\n",
        "\n",
        "        rank = cosine_similarity(query_embeddings,corpus_embeddings)\n",
        "        rank_dict = {i: rank[0, i] for i in range(len(rank[0]))}\n",
        "\n",
        "        dense_rank = dict(sorted(rank_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "        return dense_rank\n",
        "\n",
        "    def get_result(self, corpus, query, n:int=10):\n",
        "        dense_rank = self.rank(corpus, query)\n",
        "        corpus_id = list(dense_rank.keys())\n",
        "        result = []\n",
        "        for id in corpus_id[:n]:\n",
        "            result.append(corpus[id])\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ygQOVUsJPw",
        "outputId": "97fd1275-19ff-4081-9a55-eaecb22bbaef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10058\n",
            "Encoding process using cuda:0\n",
            "10058 corpus separated into 101 smaller batch\n",
            "Finish embed corpus, batch 1\n",
            "Finish embed corpus, batch 2\n",
            "Finish embed corpus, batch 3\n",
            "Finish embed corpus, batch 4\n",
            "Finish embed corpus, batch 5\n",
            "Finish embed corpus, batch 6\n",
            "Finish embed corpus, batch 7\n",
            "Finish embed corpus, batch 8\n",
            "Finish embed corpus, batch 9\n",
            "Finish embed corpus, batch 10\n",
            "Finish embed corpus, batch 11\n",
            "Finish embed corpus, batch 12\n",
            "Finish embed corpus, batch 13\n",
            "Finish embed corpus, batch 14\n",
            "Finish embed corpus, batch 15\n",
            "Finish embed corpus, batch 16\n",
            "Finish embed corpus, batch 17\n",
            "Finish embed corpus, batch 18\n",
            "Finish embed corpus, batch 19\n",
            "Finish embed corpus, batch 20\n",
            "Finish embed corpus, batch 21\n",
            "Finish embed corpus, batch 22\n",
            "Finish embed corpus, batch 23\n",
            "Finish embed corpus, batch 24\n",
            "Finish embed corpus, batch 25\n",
            "Finish embed corpus, batch 26\n",
            "Finish embed corpus, batch 27\n",
            "Finish embed corpus, batch 28\n",
            "Finish embed corpus, batch 29\n",
            "Finish embed corpus, batch 30\n",
            "Finish embed corpus, batch 31\n",
            "Finish embed corpus, batch 32\n",
            "Finish embed corpus, batch 33\n",
            "Finish embed corpus, batch 34\n",
            "Finish embed corpus, batch 35\n",
            "Finish embed corpus, batch 36\n",
            "Finish embed corpus, batch 37\n",
            "Finish embed corpus, batch 38\n",
            "Finish embed corpus, batch 39\n",
            "Finish embed corpus, batch 40\n",
            "Finish embed corpus, batch 41\n",
            "Finish embed corpus, batch 42\n",
            "Finish embed corpus, batch 43\n",
            "Finish embed corpus, batch 44\n",
            "Finish embed corpus, batch 45\n",
            "Finish embed corpus, batch 46\n",
            "Finish embed corpus, batch 47\n",
            "Finish embed corpus, batch 48\n",
            "Finish embed corpus, batch 49\n",
            "Finish embed corpus, batch 50\n",
            "Finish embed corpus, batch 51\n",
            "Finish embed corpus, batch 52\n",
            "Finish embed corpus, batch 53\n",
            "Finish embed corpus, batch 54\n",
            "Finish embed corpus, batch 55\n",
            "Finish embed corpus, batch 56\n",
            "Finish embed corpus, batch 57\n",
            "Finish embed corpus, batch 58\n",
            "Finish embed corpus, batch 59\n",
            "Finish embed corpus, batch 60\n",
            "Finish embed corpus, batch 61\n",
            "Finish embed corpus, batch 62\n",
            "Finish embed corpus, batch 63\n",
            "Finish embed corpus, batch 64\n",
            "Finish embed corpus, batch 65\n",
            "Finish embed corpus, batch 66\n",
            "Finish embed corpus, batch 67\n",
            "Finish embed corpus, batch 68\n",
            "Finish embed corpus, batch 69\n",
            "Finish embed corpus, batch 70\n",
            "Finish embed corpus, batch 71\n",
            "Finish embed corpus, batch 72\n",
            "Finish embed corpus, batch 73\n",
            "Finish embed corpus, batch 74\n",
            "Finish embed corpus, batch 75\n",
            "Finish embed corpus, batch 76\n",
            "Finish embed corpus, batch 77\n",
            "Finish embed corpus, batch 78\n",
            "Finish embed corpus, batch 79\n",
            "Finish embed corpus, batch 80\n",
            "Finish embed corpus, batch 81\n",
            "Finish embed corpus, batch 82\n",
            "Finish embed corpus, batch 83\n",
            "Finish embed corpus, batch 84\n",
            "Finish embed corpus, batch 85\n",
            "Finish embed corpus, batch 86\n",
            "Finish embed corpus, batch 87\n",
            "Finish embed corpus, batch 88\n",
            "Finish embed corpus, batch 89\n",
            "Finish embed corpus, batch 90\n",
            "Finish embed corpus, batch 91\n",
            "Finish embed corpus, batch 92\n",
            "Finish embed corpus, batch 93\n",
            "Finish embed corpus, batch 94\n",
            "Finish embed corpus, batch 95\n",
            "Finish embed corpus, batch 96\n",
            "Finish embed corpus, batch 97\n",
            "Finish embed corpus, batch 98\n",
            "Finish embed corpus, batch 99\n",
            "Finish embed corpus, batch 100\n",
            "Finish embed corpus, batch 101\n",
            "temp/temp_1.npy\n",
            "Success corpus append\n",
            "temp/temp_2.npy\n",
            "Success corpus append\n",
            "temp/temp_3.npy\n",
            "Success corpus append\n",
            "temp/temp_4.npy\n",
            "Success corpus append\n",
            "temp/temp_5.npy\n",
            "Success corpus append\n",
            "temp/temp_6.npy\n",
            "Success corpus append\n",
            "temp/temp_7.npy\n",
            "Success corpus append\n",
            "temp/temp_8.npy\n",
            "Success corpus append\n",
            "temp/temp_9.npy\n",
            "Success corpus append\n",
            "temp/temp_10.npy\n",
            "Success corpus append\n",
            "temp/temp_11.npy\n",
            "Success corpus append\n",
            "temp/temp_12.npy\n",
            "Success corpus append\n",
            "temp/temp_13.npy\n",
            "Success corpus append\n",
            "temp/temp_14.npy\n",
            "Success corpus append\n",
            "temp/temp_15.npy\n",
            "Success corpus append\n",
            "temp/temp_16.npy\n",
            "Success corpus append\n",
            "temp/temp_17.npy\n",
            "Success corpus append\n",
            "temp/temp_18.npy\n",
            "Success corpus append\n",
            "temp/temp_19.npy\n",
            "Success corpus append\n",
            "temp/temp_20.npy\n",
            "Success corpus append\n",
            "temp/temp_21.npy\n",
            "Success corpus append\n",
            "temp/temp_22.npy\n",
            "Success corpus append\n",
            "temp/temp_23.npy\n",
            "Success corpus append\n",
            "temp/temp_24.npy\n",
            "Success corpus append\n",
            "temp/temp_25.npy\n",
            "Success corpus append\n",
            "temp/temp_26.npy\n",
            "Success corpus append\n",
            "temp/temp_27.npy\n",
            "Success corpus append\n",
            "temp/temp_28.npy\n",
            "Success corpus append\n",
            "temp/temp_29.npy\n",
            "Success corpus append\n",
            "temp/temp_30.npy\n",
            "Success corpus append\n",
            "temp/temp_31.npy\n",
            "Success corpus append\n",
            "temp/temp_32.npy\n",
            "Success corpus append\n",
            "temp/temp_33.npy\n",
            "Success corpus append\n",
            "temp/temp_34.npy\n",
            "Success corpus append\n",
            "temp/temp_35.npy\n",
            "Success corpus append\n",
            "temp/temp_36.npy\n",
            "Success corpus append\n",
            "temp/temp_37.npy\n",
            "Success corpus append\n",
            "temp/temp_38.npy\n",
            "Success corpus append\n",
            "temp/temp_39.npy\n",
            "Success corpus append\n",
            "temp/temp_40.npy\n",
            "Success corpus append\n",
            "temp/temp_41.npy\n",
            "Success corpus append\n",
            "temp/temp_42.npy\n",
            "Success corpus append\n",
            "temp/temp_43.npy\n",
            "Success corpus append\n",
            "temp/temp_44.npy\n",
            "Success corpus append\n",
            "temp/temp_45.npy\n",
            "Success corpus append\n",
            "temp/temp_46.npy\n",
            "Success corpus append\n",
            "temp/temp_47.npy\n",
            "Success corpus append\n",
            "temp/temp_48.npy\n",
            "Success corpus append\n",
            "temp/temp_49.npy\n",
            "Success corpus append\n",
            "temp/temp_50.npy\n",
            "Success corpus append\n",
            "temp/temp_51.npy\n",
            "Success corpus append\n",
            "temp/temp_52.npy\n",
            "Success corpus append\n",
            "temp/temp_53.npy\n",
            "Success corpus append\n",
            "temp/temp_54.npy\n",
            "Success corpus append\n",
            "temp/temp_55.npy\n",
            "Success corpus append\n",
            "temp/temp_56.npy\n",
            "Success corpus append\n",
            "temp/temp_57.npy\n",
            "Success corpus append\n",
            "temp/temp_58.npy\n",
            "Success corpus append\n",
            "temp/temp_59.npy\n",
            "Success corpus append\n",
            "temp/temp_60.npy\n",
            "Success corpus append\n",
            "temp/temp_61.npy\n",
            "Success corpus append\n",
            "temp/temp_62.npy\n",
            "Success corpus append\n",
            "temp/temp_63.npy\n",
            "Success corpus append\n",
            "temp/temp_64.npy\n",
            "Success corpus append\n",
            "temp/temp_65.npy\n",
            "Success corpus append\n",
            "temp/temp_66.npy\n",
            "Success corpus append\n",
            "temp/temp_67.npy\n",
            "Success corpus append\n",
            "temp/temp_68.npy\n",
            "Success corpus append\n",
            "temp/temp_69.npy\n",
            "Success corpus append\n",
            "temp/temp_70.npy\n",
            "Success corpus append\n",
            "temp/temp_71.npy\n",
            "Success corpus append\n",
            "temp/temp_72.npy\n",
            "Success corpus append\n",
            "temp/temp_73.npy\n",
            "Success corpus append\n",
            "temp/temp_74.npy\n",
            "Success corpus append\n",
            "temp/temp_75.npy\n",
            "Success corpus append\n",
            "temp/temp_76.npy\n",
            "Success corpus append\n",
            "temp/temp_77.npy\n",
            "Success corpus append\n",
            "temp/temp_78.npy\n",
            "Success corpus append\n",
            "temp/temp_79.npy\n",
            "Success corpus append\n",
            "temp/temp_80.npy\n",
            "Success corpus append\n",
            "temp/temp_81.npy\n",
            "Success corpus append\n",
            "temp/temp_82.npy\n",
            "Success corpus append\n",
            "temp/temp_83.npy\n",
            "Success corpus append\n",
            "temp/temp_84.npy\n",
            "Success corpus append\n",
            "temp/temp_85.npy\n",
            "Success corpus append\n",
            "temp/temp_86.npy\n",
            "Success corpus append\n",
            "temp/temp_87.npy\n",
            "Success corpus append\n",
            "temp/temp_88.npy\n",
            "Success corpus append\n",
            "temp/temp_89.npy\n",
            "Success corpus append\n",
            "temp/temp_90.npy\n",
            "Success corpus append\n",
            "temp/temp_91.npy\n",
            "Success corpus append\n",
            "temp/temp_92.npy\n",
            "Success corpus append\n",
            "temp/temp_93.npy\n",
            "Success corpus append\n",
            "temp/temp_94.npy\n",
            "Success corpus append\n",
            "temp/temp_95.npy\n",
            "Success corpus append\n",
            "temp/temp_96.npy\n",
            "Success corpus append\n",
            "temp/temp_97.npy\n",
            "Success corpus append\n",
            "temp/temp_98.npy\n",
            "Success corpus append\n",
            "temp/temp_99.npy\n",
            "Success corpus append\n",
            "temp/temp_100.npy\n",
            "Success corpus append\n",
            "temp/temp_101.npy\n",
            "Success corpus append\n",
            "Finish embed corpus\n",
            "[[ 0.0095153  -0.16766974 -0.01275068 ...  0.01583043  0.00041984\n",
            "  -0.07892595]\n",
            " [-0.07919548 -0.14457496 -0.01306355 ...  0.00511781  0.04691638\n",
            "  -0.0210853 ]\n",
            " [-0.07919548 -0.14457496 -0.01306355 ...  0.00511781  0.04691638\n",
            "  -0.0210853 ]\n",
            " ...\n",
            " [ 0.00886752 -0.02837358 -0.00408306 ...  0.05469499 -0.13628873\n",
            "  -0.07806261]\n",
            " [ 0.03365299  0.01722499 -0.00438239 ... -0.08646187 -0.01311595\n",
            "  -0.09268237]\n",
            " [-0.0147673  -0.2811067  -0.00954759 ... -0.01034249 -0.01904682\n",
            "  -0.01714443]]\n"
          ]
        }
      ],
      "source": [
        "model = SemanticSearch()\n",
        "model.load_pretrained()\n",
        "\n",
        "df = pd.read_csv('data_obat_fix_ordered.csv')\n",
        "sentences = df['summary'].to_list()\n",
        "\n",
        "print(len(sentences))\n",
        "final_embedding = model.process(sentences)\n",
        "print(final_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkBIqYlzsJZ3",
        "outputId": "d2ad8280-009c-4eec-e0f2-698c827c1fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding process using cpu\n",
            "Finish embed query\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['borobudur kamal pil kamal membantu mengurangi gatal  gatal kulit',\n",
              " 'kapsida kembang bulan kapsul membantu meringankan gatal  gatal  bisul  koreng jerawat',\n",
              " 'borobudur kamal kapsul kamal membantu mengurangi gatal  gatal kulit',\n",
              " 'borobudur darsi pil darsi membantu mengurangi jerawat  bisul  gatal  gatal',\n",
              " 'sido muncul aluss kapsul aluss mencegah mengobati jerawat  menghilangkan bercak  bercak hitam kulit  menjaga kulit halus bersih',\n",
              " 'triamcorta krim triamcinolone acetonide mengurangi peradangan gatal disebabkan kelai kulit responsif kortikosteroid efek anti inflamasi  anti alergi  anti pruritus gatal',\n",
              " 'apolar cream krim desonide mengatasi kondisi kulit mengalami inflamasi akibat penyakit dermatitis kontak atopik',\n",
              " 'apolar cream krim desonide mengatasi kondisi kulit mengalami inflamasi akibat penyakit dermatitis kontak atopik',\n",
              " 'rodeca lotion  asam salisilat meringankan gatal disebabkan biang keringat',\n",
              " 'borobudur darsi kapsul darsi membantu mengurangi jerawat  bisul  gatal  gatal']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('C:/Users/Geraldus Wilsen/Documents/ProjectRekomendasiObat/data/data_obat_fix_ordered.csv')\n",
        "corpus = df['summary'].to_list()\n",
        "query = \"pil untuk mengurangi gatal di kulit\"\n",
        "model = SemanticSearch()\n",
        "model.load_pretrained()\n",
        "model.get_result(corpus, query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
