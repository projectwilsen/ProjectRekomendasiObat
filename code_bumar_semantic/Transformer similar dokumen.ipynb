{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "julian-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5905dc9eb224036ad19dcc2c000cefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe488240791a45ce9bc40f8f6dfb948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc20964ebf154a0ebc255e15a20b757a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ced0c6fbbfb48b2b46e0fe8a76d22ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[torch.Size([15, 768]),\n",
       " torch.Size([12, 768]),\n",
       " torch.Size([10, 768]),\n",
       " torch.Size([15, 768]),\n",
       " torch.Size([10, 768])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "documents = [\n",
    "    \"That restaurant was not as good as the last movie I watched.\",\n",
    "    \"I'm selling a used car in good condition\",\n",
    "    \"Food was okay, the rest so so\",\n",
    "    \"I love cats, but don't really like hyenas\",\n",
    "    \"On the road, you must be careful\",\n",
    "]\n",
    "\n",
    "vectors = [\n",
    "  # tokenize the document, return it as PyTorch tensors (vectors),\n",
    "  # and pass it onto the model\n",
    "  model(**tokenizer(document, return_tensors='pt'))[0].detach().squeeze()\n",
    "  for document in documents\n",
    "]\n",
    "\n",
    "[v.size() for v in vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sufficient-malta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768]),\n",
       " torch.Size([768])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
    "\n",
    "[v.size() for v in averaged_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "desirable-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(document: str) -> torch.Tensor:\n",
    "    tokens = tokenizer(document, return_tensors='pt')\n",
    "    vector = model(**tokens)[0].detach().squeeze()\n",
    "    return torch.mean(vector, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overall-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "index = faiss.IndexIDMap(faiss.IndexFlatIP(768)) # the size of our vector space\n",
    "# index all the documents, we need them as numpy arrays first\n",
    "index.add_with_ids(\n",
    "    np.array([t.numpy() for t in averaged_vectors]),\n",
    "    # the IDs will be 0 to len(documents)\n",
    "    np.array(range(0, len(documents))))\n",
    "\n",
    "def search(query: str, k=1):\n",
    "    encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
    "    top_k = index.search(encoded_query, k)\n",
    "    scores = top_k[0][0]\n",
    "    results = [documents[_id] for _id in top_k[1][0]]\n",
    "    return list(zip(results, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prospective-excuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On the road, you must be careful', -3.4028235e+38),\n",
       " ('On the road, you must be careful', -3.4028235e+38)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]\n",
    "\n",
    "search(documents[1], k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "substantial-timeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On the road, you must be careful', -3.4028235e+38),\n",
       " ('On the road, you must be careful', -3.4028235e+38)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"I know how to drive\", k=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
